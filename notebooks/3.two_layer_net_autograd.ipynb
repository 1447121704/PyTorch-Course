{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Tensor和autograd\n",
    "-------------------------------\n",
    "\n",
    "PyTorch的一个重要功能就是autograd，也就是说只要定义了forward pass(前向神经网络)，计算了loss之后，PyTorch可以自动求导计算模型所有参数的梯度。\n",
    "\n",
    "一个PyTorch的Tensor表示计算图中的一个节点。如果``x``是一个Tensor并且``x.requires_grad=True``那么``x.grad``是另一个储存着``x``当前梯度(相对于一个scalar，常常是loss)的向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30369562.0\n",
      "1 27529672.0\n",
      "2 28036926.0\n",
      "3 27603856.0\n",
      "4 23998504.0\n",
      "5 17445446.0\n",
      "6 10908277.0\n",
      "7 6170470.5\n",
      "8 3488673.75\n",
      "9 2097048.75\n",
      "10 1393327.125\n",
      "11 1015624.1875\n",
      "12 794099.8125\n",
      "13 649693.5\n",
      "14 546475.3125\n",
      "15 467557.0625\n",
      "16 404509.625\n",
      "17 352759.09375\n",
      "18 309498.8125\n",
      "19 272898.0625\n",
      "20 241668.375\n",
      "21 214922.671875\n",
      "22 191827.03125\n",
      "23 171756.84375\n",
      "24 154204.0\n",
      "25 138826.90625\n",
      "26 125322.65625\n",
      "27 113416.203125\n",
      "28 102883.8203125\n",
      "29 93525.3046875\n",
      "30 85183.1171875\n",
      "31 77723.78125\n",
      "32 71038.046875\n",
      "33 65029.9765625\n",
      "34 59621.921875\n",
      "35 54744.87109375\n",
      "36 50335.578125\n",
      "37 46343.12109375\n",
      "38 42725.38671875\n",
      "39 39440.62109375\n",
      "40 36452.37890625\n",
      "41 33727.390625\n",
      "42 31237.224609375\n",
      "43 28959.123046875\n",
      "44 26870.97265625\n",
      "45 24956.08203125\n",
      "46 23197.55859375\n",
      "47 21581.00390625\n",
      "48 20093.318359375\n",
      "49 18721.54296875\n",
      "50 17455.63671875\n",
      "51 16286.9814453125\n",
      "52 15206.484375\n",
      "53 14206.5234375\n",
      "54 13279.990234375\n",
      "55 12421.716796875\n",
      "56 11625.6201171875\n",
      "57 10886.41796875\n",
      "58 10199.80859375\n",
      "59 9561.0703125\n",
      "60 8966.953125\n",
      "61 8413.7060546875\n",
      "62 7898.580078125\n",
      "63 7418.2744140625\n",
      "64 6970.02734375\n",
      "65 6551.876953125\n",
      "66 6161.26025390625\n",
      "67 5796.33984375\n",
      "68 5455.146484375\n",
      "69 5135.9970703125\n",
      "70 4837.662109375\n",
      "71 4557.974609375\n",
      "72 4296.02587890625\n",
      "73 4050.91455078125\n",
      "74 3821.06396484375\n",
      "75 3605.41259765625\n",
      "76 3403.169189453125\n",
      "77 3213.447509765625\n",
      "78 3035.1845703125\n",
      "79 2867.68115234375\n",
      "80 2710.348388671875\n",
      "81 2562.3935546875\n",
      "82 2423.147216796875\n",
      "83 2292.350830078125\n",
      "84 2169.16455078125\n",
      "85 2053.269287109375\n",
      "86 1943.9697265625\n",
      "87 1840.9114990234375\n",
      "88 1743.7593994140625\n",
      "89 1652.111572265625\n",
      "90 1565.6612548828125\n",
      "91 1484.0743408203125\n",
      "92 1407.012451171875\n",
      "93 1334.2525634765625\n",
      "94 1265.5052490234375\n",
      "95 1200.561767578125\n",
      "96 1139.182861328125\n",
      "97 1081.150146484375\n",
      "98 1026.2530517578125\n",
      "99 974.3346557617188\n",
      "100 925.206298828125\n",
      "101 878.736572265625\n",
      "102 834.7527465820312\n",
      "103 793.091064453125\n",
      "104 753.6366577148438\n",
      "105 716.2752685546875\n",
      "106 680.8699340820312\n",
      "107 647.3223876953125\n",
      "108 615.5352783203125\n",
      "109 585.4192504882812\n",
      "110 556.8613891601562\n",
      "111 529.778564453125\n",
      "112 504.08349609375\n",
      "113 479.70269775390625\n",
      "114 456.5566711425781\n",
      "115 434.5901794433594\n",
      "116 413.7417297363281\n",
      "117 393.93585205078125\n",
      "118 375.12518310546875\n",
      "119 357.25592041015625\n",
      "120 340.287353515625\n",
      "121 324.1589050292969\n",
      "122 308.8302917480469\n",
      "123 294.2562561035156\n",
      "124 280.40411376953125\n",
      "125 267.23529052734375\n",
      "126 254.70590209960938\n",
      "127 242.79298400878906\n",
      "128 231.45947265625\n",
      "129 220.67864990234375\n",
      "130 210.42359924316406\n",
      "131 200.66281127929688\n",
      "132 191.37213134765625\n",
      "133 182.5299530029297\n",
      "134 174.1095733642578\n",
      "135 166.09283447265625\n",
      "136 158.4606475830078\n",
      "137 151.19480895996094\n",
      "138 144.26968383789062\n",
      "139 137.67364501953125\n",
      "140 131.39382934570312\n",
      "141 125.40763854980469\n",
      "142 119.70387268066406\n",
      "143 114.26878356933594\n",
      "144 109.08836364746094\n",
      "145 104.14935302734375\n",
      "146 99.44161224365234\n",
      "147 94.95455169677734\n",
      "148 90.67465209960938\n",
      "149 86.59608459472656\n",
      "150 82.70779418945312\n",
      "151 78.99627685546875\n",
      "152 75.45738983154297\n",
      "153 72.08018493652344\n",
      "154 68.86035919189453\n",
      "155 65.78683471679688\n",
      "156 62.855934143066406\n",
      "157 60.058189392089844\n",
      "158 57.38935852050781\n",
      "159 54.840782165527344\n",
      "160 52.40962600708008\n",
      "161 50.08891677856445\n",
      "162 47.8731689453125\n",
      "163 45.75837707519531\n",
      "164 43.738590240478516\n",
      "165 41.810394287109375\n",
      "166 39.96910095214844\n",
      "167 38.211463928222656\n",
      "168 36.53209686279297\n",
      "169 34.929256439208984\n",
      "170 33.39773941040039\n",
      "171 31.934959411621094\n",
      "172 30.537841796875\n",
      "173 29.202695846557617\n",
      "174 27.927587509155273\n",
      "175 26.708885192871094\n",
      "176 25.544822692871094\n",
      "177 24.432527542114258\n",
      "178 23.369565963745117\n",
      "179 22.35403823852539\n",
      "180 21.38347053527832\n",
      "181 20.455902099609375\n",
      "182 19.568695068359375\n",
      "183 18.72093963623047\n",
      "184 17.9110107421875\n",
      "185 17.136072158813477\n",
      "186 16.39609146118164\n",
      "187 15.688085556030273\n",
      "188 15.011492729187012\n",
      "189 14.364477157592773\n",
      "190 13.745914459228516\n",
      "191 13.154133796691895\n",
      "192 12.588301658630371\n",
      "193 12.04749870300293\n",
      "194 11.530033111572266\n",
      "195 11.035097122192383\n",
      "196 10.561996459960938\n",
      "197 10.109487533569336\n",
      "198 9.67666244506836\n",
      "199 9.2623872756958\n",
      "200 8.866561889648438\n",
      "201 8.487176895141602\n",
      "202 8.124982833862305\n",
      "203 7.77806282043457\n",
      "204 7.446126937866211\n",
      "205 7.128879070281982\n",
      "206 6.824840545654297\n",
      "207 6.53418493270874\n",
      "208 6.256248474121094\n",
      "209 5.990139007568359\n",
      "210 5.7357869148254395\n",
      "211 5.49208927154541\n",
      "212 5.2587809562683105\n",
      "213 5.035531997680664\n",
      "214 4.822030544281006\n",
      "215 4.617486953735352\n",
      "216 4.4218339920043945\n",
      "217 4.2345685958862305\n",
      "218 4.055356025695801\n",
      "219 3.8839609622955322\n",
      "220 3.7195897102355957\n",
      "221 3.5626089572906494\n",
      "222 3.4120795726776123\n",
      "223 3.2679333686828613\n",
      "224 3.129979372024536\n",
      "225 2.9980874061584473\n",
      "226 2.871561050415039\n",
      "227 2.750498056411743\n",
      "228 2.634535312652588\n",
      "229 2.523752450942993\n",
      "230 2.417491912841797\n",
      "231 2.315836191177368\n",
      "232 2.218386173248291\n",
      "233 2.125136137008667\n",
      "234 2.0358150005340576\n",
      "235 1.950384259223938\n",
      "236 1.8684656620025635\n",
      "237 1.7900195121765137\n",
      "238 1.7148898839950562\n",
      "239 1.6430244445800781\n",
      "240 1.5741846561431885\n",
      "241 1.5081796646118164\n",
      "242 1.445082664489746\n",
      "243 1.3845348358154297\n",
      "244 1.3266228437423706\n",
      "245 1.2710553407669067\n",
      "246 1.2179771661758423\n",
      "247 1.1670706272125244\n",
      "248 1.1182209253311157\n",
      "249 1.0714614391326904\n",
      "250 1.0266305208206177\n",
      "251 0.9838260412216187\n",
      "252 0.9427748918533325\n",
      "253 0.9034774303436279\n",
      "254 0.8657512664794922\n",
      "255 0.8295950889587402\n",
      "256 0.7950475811958313\n",
      "257 0.7619398832321167\n",
      "258 0.7301834225654602\n",
      "259 0.6997958421707153\n",
      "260 0.6706204414367676\n",
      "261 0.6426944136619568\n",
      "262 0.6159462332725525\n",
      "263 0.5903399586677551\n",
      "264 0.565799355506897\n",
      "265 0.5422577857971191\n",
      "266 0.5196781158447266\n",
      "267 0.49807995557785034\n",
      "268 0.47740864753723145\n",
      "269 0.4575864374637604\n",
      "270 0.43857815861701965\n",
      "271 0.4203968346118927\n",
      "272 0.40289732813835144\n",
      "273 0.3862166404724121\n",
      "274 0.37017831206321716\n",
      "275 0.3548203110694885\n",
      "276 0.34009283781051636\n",
      "277 0.3260182738304138\n",
      "278 0.3124694228172302\n",
      "279 0.29955440759658813\n",
      "280 0.2871481776237488\n",
      "281 0.2752683162689209\n",
      "282 0.2638634443283081\n",
      "283 0.252973347902298\n",
      "284 0.24248401820659637\n",
      "285 0.2324773073196411\n",
      "286 0.22280779480934143\n",
      "287 0.21362189948558807\n",
      "288 0.20475614070892334\n",
      "289 0.19631445407867432\n",
      "290 0.1881958544254303\n",
      "291 0.18040353059768677\n",
      "292 0.1729537695646286\n",
      "293 0.16579028964042664\n",
      "294 0.1589438021183014\n",
      "295 0.15239980816841125\n",
      "296 0.14608997106552124\n",
      "297 0.1400734782218933\n",
      "298 0.13428451120853424\n",
      "299 0.12877964973449707\n",
      "300 0.12347087264060974\n",
      "301 0.1183868944644928\n",
      "302 0.11349976062774658\n",
      "303 0.10884057730436325\n",
      "304 0.10435561835765839\n",
      "305 0.10003571212291718\n",
      "306 0.09590522944927216\n",
      "307 0.09196022152900696\n",
      "308 0.08819307386875153\n",
      "309 0.08455967158079147\n",
      "310 0.08108334243297577\n",
      "311 0.07774242758750916\n",
      "312 0.0745542049407959\n",
      "313 0.07148873060941696\n",
      "314 0.06855133920907974\n",
      "315 0.06573733687400818\n",
      "316 0.06302361190319061\n",
      "317 0.06043983995914459\n",
      "318 0.05795079469680786\n",
      "319 0.0555805042386055\n",
      "320 0.05329868197441101\n",
      "321 0.051108453422784805\n",
      "322 0.04901948943734169\n",
      "323 0.04699474200606346\n",
      "324 0.04508678615093231\n",
      "325 0.04324592649936676\n",
      "326 0.04146736115217209\n",
      "327 0.0397653728723526\n",
      "328 0.03815031051635742\n",
      "329 0.03657738119363785\n",
      "330 0.035089924931526184\n",
      "331 0.033664871007204056\n",
      "332 0.032285794615745544\n",
      "333 0.030964363366365433\n",
      "334 0.02970169112086296\n",
      "335 0.02849189005792141\n",
      "336 0.027330536395311356\n",
      "337 0.026213224977254868\n",
      "338 0.025150202214717865\n",
      "339 0.024120861664414406\n",
      "340 0.02314903773367405\n",
      "341 0.022202055901288986\n",
      "342 0.021301712840795517\n",
      "343 0.020431291311979294\n",
      "344 0.019604746252298355\n",
      "345 0.01881130412220955\n",
      "346 0.018051497638225555\n",
      "347 0.017318157479166985\n",
      "348 0.016622230410575867\n",
      "349 0.015963543206453323\n",
      "350 0.015312587842345238\n",
      "351 0.014701539650559425\n",
      "352 0.014115115627646446\n",
      "353 0.013553071767091751\n",
      "354 0.013005180284380913\n",
      "355 0.012489821761846542\n",
      "356 0.011983332224190235\n",
      "357 0.011512183584272861\n",
      "358 0.01105144340544939\n",
      "359 0.010608349926769733\n",
      "360 0.010187455452978611\n",
      "361 0.009778305888175964\n",
      "362 0.009392830543220043\n",
      "363 0.009023601189255714\n",
      "364 0.008658851496875286\n",
      "365 0.008320773020386696\n",
      "366 0.00799256656318903\n",
      "367 0.007686074823141098\n",
      "368 0.007385294884443283\n",
      "369 0.007096902001649141\n",
      "370 0.006820491049438715\n",
      "371 0.00655110040679574\n",
      "372 0.006300550885498524\n",
      "373 0.006052975542843342\n",
      "374 0.005823848769068718\n",
      "375 0.005598883610218763\n",
      "376 0.005385705269873142\n",
      "377 0.005176822654902935\n",
      "378 0.0049790386110544205\n",
      "379 0.004787936341017485\n",
      "380 0.004609991330653429\n",
      "381 0.0044362908229231834\n",
      "382 0.004267551004886627\n",
      "383 0.004106976557523012\n",
      "384 0.0039528170600533485\n",
      "385 0.003805467626079917\n",
      "386 0.003664741525426507\n",
      "387 0.003531038761138916\n",
      "388 0.003401009365916252\n",
      "389 0.0032738407608121634\n",
      "390 0.0031534701120108366\n",
      "391 0.0030416485387831926\n",
      "392 0.002929587848484516\n",
      "393 0.0028280732221901417\n",
      "394 0.002725085476413369\n",
      "395 0.00262872944585979\n",
      "396 0.002531912177801132\n",
      "397 0.002443405333906412\n",
      "398 0.002357208402827382\n",
      "399 0.0022769253700971603\n",
      "400 0.002195862354710698\n",
      "401 0.00211996678262949\n",
      "402 0.002046305686235428\n",
      "403 0.0019767116755247116\n",
      "404 0.0019075660966336727\n",
      "405 0.0018460929859429598\n",
      "406 0.0017827397678047419\n",
      "407 0.0017202571034431458\n",
      "408 0.0016628250014036894\n",
      "409 0.0016110664000734687\n",
      "410 0.001557340961880982\n",
      "411 0.0015078289434313774\n",
      "412 0.001457524485886097\n",
      "413 0.0014103748835623264\n",
      "414 0.001363136456348002\n",
      "415 0.00132139609195292\n",
      "416 0.0012796616647392511\n",
      "417 0.0012395591475069523\n",
      "418 0.0012022608425468206\n",
      "419 0.001163604436442256\n",
      "420 0.0011263168416917324\n",
      "421 0.0010916098253801465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 0.0010577118955552578\n",
      "423 0.0010261309798806906\n",
      "424 0.0009933850960806012\n",
      "425 0.0009646841790527105\n",
      "426 0.0009370717452839017\n",
      "427 0.0009089648956432939\n",
      "428 0.0008828708669170737\n",
      "429 0.0008563525043427944\n",
      "430 0.0008310276316478848\n",
      "431 0.0008066720911301672\n",
      "432 0.0007830946706235409\n",
      "433 0.0007609119638800621\n",
      "434 0.000739025475922972\n",
      "435 0.0007178643136285245\n",
      "436 0.0006986127118580043\n",
      "437 0.0006796512752771378\n",
      "438 0.0006603989750146866\n",
      "439 0.000642913393676281\n",
      "440 0.0006256248452700675\n",
      "441 0.0006089266971684992\n",
      "442 0.000592652359046042\n",
      "443 0.0005774443270638585\n",
      "444 0.0005624277982860804\n",
      "445 0.0005478737875819206\n",
      "446 0.0005326138925738633\n",
      "447 0.0005187002243474126\n",
      "448 0.0005062900600023568\n",
      "449 0.0004932465380989015\n",
      "450 0.00047971931053325534\n",
      "451 0.0004677766119129956\n",
      "452 0.0004574775230139494\n",
      "453 0.00044540062663145363\n",
      "454 0.0004346564819570631\n",
      "455 0.00042371469317004085\n",
      "456 0.0004140151431784034\n",
      "457 0.0004040310741402209\n",
      "458 0.00039397526415996253\n",
      "459 0.000384875456802547\n",
      "460 0.00037615938344970345\n",
      "461 0.0003677375498227775\n",
      "462 0.00035846870741806924\n",
      "463 0.00035014405148103833\n",
      "464 0.0003421098808757961\n",
      "465 0.00033425213769078255\n",
      "466 0.00032701477175578475\n",
      "467 0.00031969917472451925\n",
      "468 0.0003128230746369809\n",
      "469 0.00030562226311303675\n",
      "470 0.0002987845509778708\n",
      "471 0.0002920453262049705\n",
      "472 0.00028578253113664687\n",
      "473 0.00027990457601845264\n",
      "474 0.0002736151509452611\n",
      "475 0.000268513394985348\n",
      "476 0.00026229029754176736\n",
      "477 0.00025714217917993665\n",
      "478 0.0002515348605811596\n",
      "479 0.0002457885129842907\n",
      "480 0.00024163073976524174\n",
      "481 0.00023660017177462578\n",
      "482 0.00023133307695388794\n",
      "483 0.00022652186453342438\n",
      "484 0.0002224521740572527\n",
      "485 0.00021765528072137386\n",
      "486 0.00021302349341567606\n",
      "487 0.00020896575006190687\n",
      "488 0.00020529967150650918\n",
      "489 0.00020113539358135313\n",
      "490 0.0001980047090910375\n",
      "491 0.0001935339387273416\n",
      "492 0.00018959210137836635\n",
      "493 0.0001864991063484922\n",
      "494 0.00018289312720298767\n",
      "495 0.00017927444423548877\n",
      "496 0.00017610564827919006\n",
      "497 0.00017254779231734574\n",
      "498 0.00016922823851928115\n",
      "499 0.0001662988361204043\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N 是 batch size; D_in 是 input dimension;\n",
    "# H 是 hidden dimension; D_out 是 output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建随机的Tensor来保存输入和输出\n",
    "# 设定requires_grad=False表示在反向传播的时候我们不需要计算gradient\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# 创建随机的Tensor和权重。\n",
    "# 设置requires_grad=True表示我们希望反向传播的时候计算Tensor的gradient\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 前向传播:通过Tensor预测y；这个和普通的神经网络的前向传播没有任何不同，\n",
    "    # 但是我们不需要保存网络的中间运算结果，因为我们不需要手动计算反向传播。\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # 通过前向传播计算loss\n",
    "    # loss是一个形状为(1，)的Tensor\n",
    "    # loss.item()可以给我们返回一个loss的scalar\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # PyTorch给我们提供了autograd的方法做反向传播。如果一个Tensor的requires_grad=True，\n",
    "    # backward会自动计算loss相对于每个Tensor的gradient。在backward之后，\n",
    "    # w1.grad和w2.grad会包含两个loss相对于两个Tensor的gradient信息。\n",
    "    loss.backward()\n",
    "\n",
    "    # 我们可以手动做gradient descent(后面我们会介绍自动的方法)。\n",
    "    # 用torch.no_grad()包含以下statements，因为w1和w2都是requires_grad=True，\n",
    "    # 但是在更新weights之后我们并不需要再做autograd。\n",
    "    # 另一种方法是在weight.data和weight.grad.data上做操作，这样就不会对grad产生影响。\n",
    "    # tensor.data会我们一个tensor，这个tensor和原来的tensor指向相同的内存空间，\n",
    "    # 但是不会记录计算图的历史。\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
